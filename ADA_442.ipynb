{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4119 entries, 0 to 4118\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             4119 non-null   int64  \n",
      " 1   job             4119 non-null   object \n",
      " 2   marital         4119 non-null   object \n",
      " 3   education       4119 non-null   object \n",
      " 4   default         4119 non-null   object \n",
      " 5   housing         4119 non-null   object \n",
      " 6   loan            4119 non-null   object \n",
      " 7   contact         4119 non-null   object \n",
      " 8   month           4119 non-null   object \n",
      " 9   day_of_week     4119 non-null   object \n",
      " 10  duration        4119 non-null   int64  \n",
      " 11  campaign        4119 non-null   int64  \n",
      " 12  pdays           4119 non-null   int64  \n",
      " 13  previous        4119 non-null   int64  \n",
      " 14  poutcome        4119 non-null   object \n",
      " 15  emp.var.rate    4119 non-null   float64\n",
      " 16  cons.price.idx  4119 non-null   float64\n",
      " 17  cons.conf.idx   4119 non-null   float64\n",
      " 18  euribor3m       4119 non-null   float64\n",
      " 19  nr.employed     4119 non-null   float64\n",
      " 20  y               4119 non-null   object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 675.9+ KB\n",
      "None\n",
      "First Few Rows of the Dataset:\n",
      "   age          job  marital          education default  housing     loan  \\\n",
      "0   30  blue-collar  married           basic.9y      no      yes       no   \n",
      "1   39     services   single        high.school      no       no       no   \n",
      "2   25     services  married        high.school      no      yes       no   \n",
      "3   38     services  married           basic.9y      no  unknown  unknown   \n",
      "4   47       admin.  married  university.degree      no      yes       no   \n",
      "\n",
      "     contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
      "0   cellular   may         fri  ...         2    999         0  nonexistent   \n",
      "1  telephone   may         fri  ...         4    999         0  nonexistent   \n",
      "2  telephone   jun         wed  ...         1    999         0  nonexistent   \n",
      "3  telephone   jun         fri  ...         3    999         0  nonexistent   \n",
      "4   cellular   nov         mon  ...         1    999         0  nonexistent   \n",
      "\n",
      "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
      "0         -1.8          92.893          -46.2      1.313       5099.1  no  \n",
      "1          1.1          93.994          -36.4      4.855       5191.0  no  \n",
      "2          1.4          94.465          -41.8      4.962       5228.1  no  \n",
      "3          1.4          94.465          -41.8      4.959       5228.1  no  \n",
      "4         -0.1          93.200          -42.0      4.191       5195.8  no  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Missing Values in the Dataset:\n",
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp.var.rate      0\n",
      "cons.price.idx    0\n",
      "cons.conf.idx     0\n",
      "euribor3m         0\n",
      "nr.employed       0\n",
      "y                 0\n",
      "dtype: int64\n",
      "Logistic Regression Scores:\n",
      "{'accuracy': 0.9053398058252428, 'precision': 0.6206896551724138, 'recall': 0.391304347826087, 'f1': 0.48}\n",
      "Random Forest Scores:\n",
      "{'accuracy': 0.9016990291262136, 'precision': 0.5873015873015873, 'recall': 0.40217391304347827, 'f1': 0.4774193548387097}\n",
      "Neural Network Scores:\n",
      "{'accuracy': 0.8895631067961165, 'precision': 0.5056179775280899, 'recall': 0.4891304347826087, 'f1': 0.4972375690607735}\n",
      "Best Random Forest Scores after Grid Search:\n",
      "{'accuracy': 0.9053398058252428, 'precision': 0.6060606060606061, 'recall': 0.43478260869565216, 'f1': 0.5063291139240507}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['top_features.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'bankadditional.csv'\n",
    "data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Information:\")\n",
    "print(data.info())\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First Few Rows of the Dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing Values in the Dataset:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Drop duplicate rows if any\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "numerical_features = ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "# Define the preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Apply the preprocessing steps\n",
    "data_preprocessed = preprocessor.fit_transform(data.drop(columns=['y']))\n",
    "target = data['y'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# Train a Random Forest model to get feature importances\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(data_preprocessed, target)\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Select top 20 features\n",
    "top_k = 20\n",
    "top_features = indices[:top_k]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_preprocessed[:, top_features], target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the models\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "mlp = MLPClassifier(random_state=42, max_iter=1000, learning_rate_init=0.001)\n",
    "\n",
    "# Train and evaluate Logistic Regression\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "logreg_scores = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_logreg),\n",
    "    'precision': precision_score(y_test, y_pred_logreg),\n",
    "    'recall': recall_score(y_test, y_pred_logreg),\n",
    "    'f1': f1_score(y_test, y_pred_logreg)\n",
    "}\n",
    "print(\"Logistic Regression Scores:\")\n",
    "print(logreg_scores)\n",
    "\n",
    "# Train and evaluate Random Forest\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "rf_scores = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'precision': precision_score(y_test, y_pred_rf),\n",
    "    'recall': recall_score(y_test, y_pred_rf),\n",
    "    'f1': f1_score(y_test, y_pred_rf)\n",
    "}\n",
    "print(\"Random Forest Scores:\")\n",
    "print(rf_scores)\n",
    "\n",
    "# Train and evaluate Neural Network\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "mlp_scores = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_mlp),\n",
    "    'precision': precision_score(y_test, y_pred_mlp),\n",
    "    'recall': recall_score(y_test, y_pred_mlp),\n",
    "    'f1': f1_score(y_test, y_pred_mlp)\n",
    "}\n",
    "print(\"Neural Network Scores:\")\n",
    "print(mlp_scores)\n",
    "\n",
    "# Grid Search for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "best_rf_scores = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_best_rf),\n",
    "    'precision': precision_score(y_test, y_pred_best_rf),\n",
    "    'recall': recall_score(y_test, y_pred_best_rf),\n",
    "    'f1': f1_score(y_test, y_pred_best_rf)\n",
    "}\n",
    "print(\"Best Random Forest Scores after Grid Search:\")\n",
    "print(best_rf_scores)\n",
    "\n",
    "# Save the best Random Forest model, preprocessor, and top features\n",
    "joblib.dump(best_rf, 'best_rf_model.pkl')\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
    "joblib.dump(top_features, 'top_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
